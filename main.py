import os, json, datetime
from pathlib import Path

import requests
from bs4 import BeautifulSoup

# ----------- è‡ªè¨‚åƒæ•¸ -----------------
URLS = [
    "https://www.ptt.cc/bbs/HardwareSale/search?q=SSD",
    "https://www.ptt.cc/bbs/HardwareSale/search?q=ç­†é›»",
]
COOKIE         = {"over18": "1"}
THRESHOLD_DATE = datetime.date(2025, 7, 28)          # åªæŠ“ 7/28(å«) ä¹‹å¾Œ
SENT_FILE      = Path(__file__).with_name("sent.json")

DISCORD_WEBHOOK = os.getenv("DISCORD_WEBHOOK")

# SOCKS5 ä»£ç†ï¼ˆéœ€ pip install requests[socks]ï¼‰
proxy_user = os.getenv("NORD_USER")
proxy_pass = os.getenv("NORD_PASS")
PROXIES = {
    "http":  f"socks5h://{proxy_user}:{proxy_pass}@nl.socks.nordhold.net:1080",
    "https": f"socks5h://{proxy_user}:{proxy_pass}@nl.socks.nordhold.net:1080",
}
# --------------------------------------

# è®€å–å·²æé†’é€£çµ
if SENT_FILE.exists():
    sent_links = set(json.loads(SENT_FILE.read_text(encoding="utf-8")))
else:
    sent_links = set()

new_links = []

def parse_page(url: str):
    """æŠ“å–å–®ä¸€æœå°‹é é¢ä¸¦ yield (post_date, title, link)"""
    res = requests.get(url, cookies=COOKIE, proxies=PROXIES, timeout=15)
    res.encoding = "utf-8"
    soup = BeautifulSoup(res.text, "html.parser")

    for ent in soup.select(".r-ent"):
        date_txt = ent.select_one(".date").text.strip()     # ä¾‹å¦‚ 7/28
        try:
            m, d = map(int, date_txt.split("/"))
            post_date = datetime.date(datetime.datetime.now().year, m, d)
        except Exception:
            continue
        if post_date < THRESHOLD_DATE:
            continue

        a_tag = ent.select_one(".title a")
        if not a_tag:
            continue
        title = a_tag.text.strip()
        link = f"https://www.ptt.cc{a_tag['href']}"
        yield post_date, title, link

for url in URLS:
    for post_date, title, link in parse_page(url):
        if link in sent_links:
            continue

        # ç™¼é€ Discord é€šçŸ¥
        message = f"{title}\nğŸ‘‰ {link}"
        requests.post(DISCORD_WEBHOOK, json={"content": message},
                      proxies=PROXIES, timeout=10)
        new_links.append(link)

# æ›´æ–° sent.json
if new_links:
    sent_links.update(new_links)
    SENT_FILE.write_text(json.dumps(list(sent_links), ensure_ascii=False, indent=2),
                         encoding="utf-8")
